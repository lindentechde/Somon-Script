/**
 * Architecture Demo - Complete Implementation Example
 *
 * This file demonstrates the refined architecture with:
 * - Clean separation of concerns
 * - Modular lexer with Strategy Pattern
 * - Application layer with use cases
 * - Error handling and metrics collection
 * - Comprehensive compilation pipeline
 */

/* eslint-disable @typescript-eslint/no-unused-vars */
/* eslint-disable no-unused-vars */

import { SomoniCompiler, demonstrateApplicationLayer } from './application-layer';
import { demonstrateModularLexer } from './modular-lexer-compatible';

export async function demonstrateCompleteArchitecture(): Promise<void> {
  console.log('üéØ Somoni Script - Complete Architecture Demonstration');
  console.log('=====================================================\n');

  console.log('This demonstration shows the refined architecture with:');
  console.log('‚úÖ Clean Architecture principles');
  console.log('‚úÖ Domain-driven design patterns');
  console.log('‚úÖ Modular lexer with Strategy Pattern');
  console.log('‚úÖ Application layer with use cases');
  console.log('‚úÖ Comprehensive error handling');
  console.log('‚úÖ Performance metrics collection');
  console.log('‚úÖ Node.js compatibility layers\n');

  // Part 1: Demonstrate modular lexer
  console.log('='.repeat(60));
  demonstrateModularLexer();
  console.log();

  // Part 2: Demonstrate application layer
  console.log('='.repeat(60));
  await demonstrateApplicationLayer();
  console.log();

  // Part 3: Demonstrate advanced compilation scenarios
  console.log('='.repeat(60));
  await demonstrateAdvancedScenarios();
  console.log();

  console.log('üéâ Complete architecture demonstration finished!');
  console.log('üìù This shows how the modular, clean architecture');
  console.log('   enables maintainable and testable code.');
}

async function demonstrateAdvancedScenarios(): Promise<void> {
  console.log('üöÄ Advanced Compilation Scenarios');
  console.log('==================================\n');

  const compiler = new SomoniCompiler();

  // Scenario 1: Complex function with type annotations
  const complexCode = `
–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ö–æ—Ä–±–∞—Ä {
    –∏—Å–º: —Å–∞—Ç—Ä;
    —Å–æ–ª: —Ä–∞“õ–∞–º;
    —Ñ–∞—ä–æ–ª: –º–∞–Ω—Ç–∏“õ”£;
}

—Ñ—É–Ω–∫—Å–∏—è –∫–æ—Ä–∫–∞—Ä–¥–∏–ö–æ—Ä–±–∞—Ä(–∫–æ—Ä–±–∞—Ä: –ö–æ—Ä–±–∞—Ä): —Å–∞—Ç—Ä {
    –∞–≥–∞—Ä (–∫–æ—Ä–±–∞—Ä.—Ñ–∞—ä–æ–ª) {
        –±–æ–∑–≥–∞—à—Ç "–ö–æ—Ä–±–∞—Ä " + –∫–æ—Ä–±–∞—Ä.–∏—Å–º + " —Ñ–∞—ä–æ–ª –∞—Å—Ç";
    } –≤–∞–≥–∞—Ä–Ω–∞ {
        –±–æ–∑–≥–∞—à—Ç "–ö–æ—Ä–±–∞—Ä " + –∫–æ—Ä–±–∞—Ä.–∏—Å–º + " “ì–∞–π—Ä–∏—Ñ–∞—ä–æ–ª –∞—Å—Ç";
    }
}

—Ç–∞“ì–π–∏—Ä—ë–±–∞–Ω–¥–∞ –∫–æ—Ä–±–∞—Ä–∏_–Ω–∞–≤: –ö–æ—Ä–±–∞—Ä = {
    –∏—Å–º: "–ê“≥–º–∞–¥",
    —Å–æ–ª: 25,
    —Ñ–∞—ä–æ–ª: –¥—É—Ä—É—Å—Ç
};

—Ä–∞“õ–∞–º –Ω–∞—Ç–∏“∑–∞ = –∫–æ—Ä–∫–∞—Ä–¥–∏–ö–æ—Ä–±–∞—Ä(–∫–æ—Ä–±–∞—Ä–∏_–Ω–∞–≤);
`;

  console.log('üìù Scenario 1: Complex Type System Usage');
  console.log('Source Code:');
  console.log(complexCode);
  console.log();

  try {
    const result1 = await compiler.compile(complexCode, {
      target: 'typescript',
      strict: true,
    });

    console.log('üìä Compilation Results:');
    console.log(`- Success: ${result1.success}`);
    console.log(`- Tokens processed: ${result1.metrics.tokenCount}`);
    console.log(`- Processing time: ${result1.metrics.totalTime.toFixed(2)}ms`);
    console.log(`- Output size: ${result1.metrics.outputSize} characters`);

    if (result1.errors.length > 0) {
      console.log('\n‚ùå Errors found:');
      result1.errors.forEach((error, index) => {
        console.log(`${index + 1}. [${error.category}] ${error.message} (line ${error.line})`);
      });
    }

    if (result1.output) {
      console.log('\nüì§ Generated Output:');
      console.log('```typescript');
      console.log(result1.output);
      console.log('```');
    }
  } catch (error) {
    console.error('‚ùå Compilation failed:', error);
  }

  console.log('\n' + '-'.repeat(50) + '\n');

  // Scenario 2: Error handling showcase
  const errorCode = `
—Ñ—É–Ω–∫—Å–∏—è –Ω–æ–¥—É—Ä—É—Å—Ç_—Å–∏–Ω—Ç–∞–∫—Å–∏—Å( {
    –±–æ–∑–≥–∞—à—Ç "–ò–Ω —Ö–∞—Ç–æ –¥–æ—Ä–∞–¥";
}

—Ç–∞“ì–π–∏—Ä—ë–±–∞–Ω–¥–∞ === –Ω–æ–º–∞—ä–ª—É–º;
`;

  console.log('üìù Scenario 2: Error Handling Demonstration');
  console.log('Source Code (with intentional errors):');
  console.log(errorCode);
  console.log();

  try {
    const result2 = await compiler.compile(errorCode);

    console.log('üìä Error Analysis:');
    console.log(`- Success: ${result2.success}`);
    console.log(`- Total errors: ${result2.errors.length}`);
    console.log(`- Total warnings: ${result2.warnings.length}`);

    if (result2.errors.length > 0) {
      console.log('\nüîç Detailed Error Analysis:');
      const errorsByCategory = groupErrorsByCategory(result2.errors);

      Object.entries(errorsByCategory).forEach(([category, errors]) => {
        console.log(`\n${category.toUpperCase()} ERRORS (${errors.length}):`);
        errors.forEach((error, index) => {
          console.log(
            `  ${index + 1}. ${error.message} at line ${error.line}, column ${error.column}`
          );
        });
      });
    }
  } catch (error) {
    console.error('‚ùå Error analysis failed:', error);
  }

  console.log('\n' + '-'.repeat(50) + '\n');

  // Scenario 3: Performance metrics
  const performanceCode = `
// Large code sample for performance testing
—Ñ—É–Ω–∫—Å–∏—è —Ñ–∏–±–æ–Ω–∞—á–∏(–Ω: —Ä–∞“õ–∞–º): —Ä–∞“õ–∞–º {
    –∞–≥–∞—Ä (–Ω <= 1) {
        –±–æ–∑–≥–∞—à—Ç –Ω;
    }
    –±–æ–∑–≥–∞—à—Ç —Ñ–∏–±–æ–Ω–∞—á–∏(–Ω - 1) + —Ñ–∏–±–æ–Ω–∞—á–∏(–Ω - 2);
}

–±–∞—Ä–æ–∏ (—Ç–∞“ì–π–∏—Ä—ë–±–∞–Ω–¥–∞ –∏ = 0; –∏ < 10; –∏++) {
    —Ä–∞“õ–∞–º –Ω–∞—Ç–∏“∑–∞ = —Ñ–∏–±–æ–Ω–∞—á–∏(–∏);
    —á–æ–ø.—Å–∞–±—Ç("–§–∏–±–æ–Ω–∞—á–∏(" + –∏ + ") = " + –Ω–∞—Ç–∏“∑–∞);
}
`;

  console.log('üìù Scenario 3: Performance Metrics Collection');
  console.log('Testing compilation performance...');

  const performanceStart = performance.now();
  const result3 = await compiler.compile(performanceCode, {
    target: 'javascript',
    optimize: true,
  });
  const totalDuration = performance.now() - performanceStart;

  console.log('\n‚ö° Performance Analysis:');
  console.log(`- Total compilation time: ${totalDuration.toFixed(2)}ms`);
  console.log(
    `- Lexical analysis: ${result3.metrics.lexicalTime.toFixed(2)}ms (${((result3.metrics.lexicalTime / totalDuration) * 100).toFixed(1)}%)`
  );
  console.log(
    `- Code generation: ${result3.metrics.codeGenTime.toFixed(2)}ms (${((result3.metrics.codeGenTime / totalDuration) * 100).toFixed(1)}%)`
  );
  console.log(
    `- Tokens per second: ${Math.round(result3.metrics.tokenCount / (result3.metrics.lexicalTime / 1000))}`
  );
  console.log(
    `- Characters per second: ${Math.round(performanceCode.length / (totalDuration / 1000))}`
  );
}

type CategorizedErrorLike = { category?: string } & Record<string, unknown>;
function groupErrorsByCategory<T extends { category?: string }>(errors: T[]): Record<string, T[]> {
  return errors.reduce<Record<string, T[]>>((groups, error) => {
    const category = (error.category && String(error.category)) || 'unknown';
    if (!groups[category]) groups[category] = [];
    groups[category].push(error);
    return groups;
  }, {});
}

// ===== EXAMPLE INTEGRATION WITH EXISTING CODEBASE =====

export function integrateWithExistingLexer(): void {
  console.log('üîó Integration Example with Existing Codebase');
  console.log('=============================================\n');

  console.log('The new modular architecture can be integrated incrementally:');
  console.log();

  console.log('1. üì¶ Keep existing lexer.ts as fallback');
  console.log('2. üÜï Use ModularLexer for new features');
  console.log('3. üîÑ Gradually migrate existing code');
  console.log('4. üß™ Run both implementations in parallel for testing');
  console.log('5. ‚úÖ Switch to new implementation when validated');
  console.log();

  console.log('Example migration strategy:');
  console.log('```typescript');
  console.log('// Phase 1: Add new lexer alongside existing one');
  console.log('import { Lexer as OldLexer } from "./lexer";');
  console.log('import { ModularLexer } from "./core/modular-lexer-compatible";');
  console.log('');
  console.log('// Phase 2: Feature flag for gradual rollout');
  console.log('const USE_NEW_LEXER = process.env.USE_MODULAR_LEXER === "true";');
  console.log('');
  console.log('function tokenize(source: string) {');
  console.log('  if (USE_NEW_LEXER) {');
  console.log('    const lexer = new ModularLexer();');
  console.log('    return lexer.tokenize(source);');
  console.log('  } else {');
  console.log('    const lexer = new OldLexer();');
  console.log('    return lexer.tokenize(source);');
  console.log('  }');
  console.log('}');
  console.log('');
  console.log('// Phase 3: Comprehensive testing');
  console.log('function validateMigration(source: string) {');
  console.log('  const oldResult = new OldLexer().tokenize(source);');
  console.log('  const newResult = new ModularLexer().tokenize(source);');
  console.log('  ');
  console.log('  // Compare results and log differences');
  console.log('  if (!tokensEqual(oldResult.tokens, newResult.tokens)) {');
  console.log('    console.warn("Token mismatch detected", { source, oldResult, newResult });');
  console.log('  }');
  console.log('}');
  console.log('```');
  console.log();

  console.log('‚úÖ This approach ensures zero-risk migration with full backwards compatibility.');
}

// Run complete demonstration if this file is executed directly
if (require.main === module) {
  demonstrateCompleteArchitecture()
    .then(() => {
      console.log('\n');
      integrateWithExistingLexer();
    })
    .catch(console.error);
}

export { SomoniCompiler, demonstrateApplicationLayer, demonstrateModularLexer };
